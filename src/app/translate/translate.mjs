import OpenAI from "openai";
import { Portkey } from "portkey-ai";
import dotenv from "dotenv";
import { append } from "./output.mjs";
import { Statistics } from "./statistics.mjs";
import { Parser } from "./parse.mjs";
import fs from "fs";

if (!process.env.NETLIFY) {
  dotenv.config();
}

const prompt = `- ä½ æ˜¯ä¸€åä¸­è‹±ç¿»è¯‘ï¼Œé€å¥ç¿»è¯‘ç»™å‡ºçš„æ–‡æœ¬
- è¶…å‡ºCET4éš¾åº¦çš„å•è¯ã€ç”Ÿåƒ»å•è¯ã€è‹±è¯­ä¿šè¯­ã€è‹±è¯­å£è¯­åŒ–çŸ­è¯­ã€ä¸“ä¸šæœ¯è¯­éœ€è¦ç»™å‡ºå…·ä½“çš„è§£é‡Šå’Œä½¿ç”¨åœºæ™¯
- è¿”å›å…¨éƒ¨å®Œæ•´çš„å¥å­ç¿»è¯‘ï¼Œä¸è¦ç¼ºå¤±é—æ¼
- ä½¿ç”¨ä»¥ä¸‹æ ¼å¼è¿”å›ï¼Œæ²¡æœ‰å…³é”®å­—æ—¶ä¸è¿”å›keywordï¼Œç¤ºä¾‹å¦‚ä¸‹ï¼š
[sentence]
en: No, didn\'t.
zh: ä¸ï¼Œæ²¡æœ‰
[sentence]
en: So these are pretty interchangeable, pretty synonymous.
zh: æ‰€ä»¥è¿™ä¸¤ä¸ªçŸ­è¯­åŸºæœ¬å¯ä»¥äº’æ¢ï¼Œæ˜¯åŒä¹‰è¯
[keyword]
word: interchangeable
explanation: å¯äº’æ›çš„ã€å¯äº¤æ›¿çš„
usage_en: The parts in these two models of cars are interchangeable, which simplifies repairs.
usage_zh: è¿™äº›æ±½è½¦é›¶ä»¶å¯ä»¥äº’æ¢ï¼Œè¿™ä½¿å¾—ç»´ä¿®å˜å¾—æ›´å®¹æ˜“
[keyword]
word: synonymous
explanation: åŒä¹‰çš„ã€åŒä¹‰è¯çš„ã€‚æŒ‡ä¸åŒè¯è¯­å¯ä»¥äº’ç›¸æ›¿æ¢è€Œä¸æ”¹å˜å¥å­çš„æ ¸å¿ƒå«ä¹‰
usage_en: "Happy" and "joyful" are often considered synonymous.
usage_zh: â€œå¿«ä¹çš„â€å’Œâ€œæ„‰å¿«çš„â€é€šå¸¸è¢«è®¤ä¸ºæ˜¯åŒä¹‰çš„ã€‚`;

// const openai = new OpenAI({
//   apiKey: process.env.API_KEY,
//   baseURL: process.env.BASE_URL,
// });

const portkey = new Portkey({
  apiKey: process.env.PORTKEY_API_KEY,
  virtualKey: process.env.PORTKEY_VIRTUAL_KEY,
});

export async function translate(input) {
  const statistics = new Statistics(input.length);
  let result = [];
  let messages = [
    { role: "system", content: prompt },
    { role: "user", content: input },
  ];

  while (true) {
    // const chatCompletion = await openai.chat.completions.create(
    //   {
    //     model: process.env.LLM_MODEL,
    //     stream: true,
    //     max_tokens: 500,
    //     thinking: { type: "disabled" },
    //     messages,
    //   },
    //   { headers: { "cf-aig-authorization": process.env.CLOUDFLARE_TOKEN } }
    // );

    const chatCompletion = await portkey.chat.completions.create({
      stream: true,
      messages,
      model: process.env.LLM_MODEL,
    });

    let finish_reason;
    let buffer = [];
    let response = "";
    const parser = new Parser();
    for await (const chunk of chatCompletion) {
      const chunkContent = chunk.choices[0].delta.content || "";
      finish_reason = chunk.choices[0].finish_reason;
      response += chunkContent;

      parser.append(chunkContent);
      buffer = parser.get().sentences;
      const count = [...result, ...buffer]
        .filter((sentence) => sentence?.en)
        .reduce((count, { en }) => count + en.length + 1, -1);
      statistics.update(Math.max(count, 0));

      if (buffer.length > 0) {
        const latestSentence = buffer[buffer.length - 1];
        if (latestSentence?.zh) {
          append(`ğŸ“ "${latestSentence.zh}"`);
          if (latestSentence.keyword?.length > 0)
            append(`ğŸ”‘ åŒ…å« ${latestSentence.keyword.length} ä¸ªå…³é”®è¯è§£é‡Š`);
        }
      }
    }

    if (finish_reason === "length") {
      result.push(...buffer.slice(0, -1));
    }
    if (finish_reason === "stop") {
      result.push(...buffer);
      break;
    }

    const endIndex = parser.get().lastIndex;
    messages.push(
      { role: "assistant", content: response.substring(0, endIndex) },
      { role: "user", content: "ç»§ç»­" }
    );
  }

  statistics.end();

  return result;
}
